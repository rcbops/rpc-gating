- job:
    name: 'Periodic-Cleanup'
    project-type: workflow
    parameters:
      - string:
          name: "INSTANCE_AGE_LIMIT"
          default: "12"
          description: |
            Hours. Instances older than this will be removed.
      - string:
          name: "PROTECTED_PREFIX"
          default: "long-running-slave|influx-|WEBHOOK-PROXY|webhook-proxy|nodepool|repo-server-|ArtifactBuilder|statsd-server-|graphite-server|grafana-server"
          description: |
            Instances that match this prefix regex will not be cleaned up.
      - string:
          name: "REGIONS"
          default: "DFW IAD ORD HKG SYD"
          description: |
            Only instances in the specified region will be cleaned up.
      - rpc_gating_params
    triggers:
      - timed: |
          H * * * 2-7
          H 13-23 * * 1
    properties:
      - build-discarder:
          days-to-keep: 3
    dsl: |
      library "rpc-gating@${RPC_GATING_BRANCH}"

      // Get list of jenkins slaves
      @NonCPS
      def getLongRunningNodes() {
        return jenkins.model.Jenkins.instance.nodes.grep {
          // Only return nodes whose name starts with one
          // of these expressions. Single use slaves won't match
          // so are filtered out.
          node -> node.name =~ /^(long-|rpc-jenkins-n)/
        }.collect {
          // node objects are not serializable so return a list
          // of names instead :(
          node -> node.name
        // master isn't in jenkins.model.Jenkins.instance.nodes so
        // add it to the filtered list.
        } + "master"
      }

      // end of functions

      common.globalWraps(){
        env.RE_JOB_REPO_NAME = "rpc-gating"
        // run node cleanups on all nodes
        def nodes = getLongRunningNodes()
        def parallel_steps = [:]
        for (int i=0; i<nodes.size(); i++){
          def nodeName = nodes[i]
          parallel_steps['node_'+nodeName] = {
            common.use_node(nodeName){
              try {
                stage("Cleanup "+nodeName){
                  dir("rpc-gating") {
                    sh "scripts/workspace_cleanup.sh"
                    sh "scripts/tmp_cleanup.sh"
                    sh "scripts/docker_cleanup.sh"
                  }
                }
              } catch(e) {
                print(e)
                common.build_failure_notify("RE")
                throw e
              }
            }
          }
        }
        parallel parallel_steps

        common.use_node("master"){
          try {
            dir("rpc-gating") {
              stage("Public Cloud Cleanup"){
                clouds_cfg = common.writeCloudsCfg()
                common.withRequestedCredentials("cloud_creds, jenkins_api_creds") {
                  sh """
                    sudo docker run \
                      --volume '${WORKSPACE}/rpc-gating:/rpc-gating' \
                      --volume '${pwd(tmp: true)}:/build-tmp' \
                      --env 'OS_CLIENT_CONFIG_FILE=/build-tmp/clouds.yaml' \
                      --env 'REGIONS=${REGIONS}' \
                      --env 'INSTANCE_AGE_LIMIT=${INSTANCE_AGE_LIMIT}' \
                      --env 'PROTECTED_PREFIX=${PROTECTED_PREFIX}' \
                      --env 'JENKINS_USERNAME=${JENKINS_USERNAME}' \
                      --env 'JENKINS_API_KEY=${JENKINS_API_KEY}' \
                      --env 'PUBCLOUD_USERNAME=${PUBCLOUD_USERNAME}' \
                      --env 'PUBCLOUD_API_KEY=${PUBCLOUD_API_KEY}' \
                      'jenkins-periodic-cleanup' \
                      python rpc-gating/scripts/periodic_cleanup.py
                  """
                }
              }
            }
          } catch(e) {
            print(e)
            common.build_failure_notify("RE")
            throw e
          }
        }
        stage("Master Log Compression"){
          node("master"){
            // Note that already compressed logs will be skipped as they
            // get renamed .gz .
            // Logs newer than 1 day are skipped to prevent compressing
            // the logs from running builds.
            sh """#!/bin/bash
              cd /var/lib/jenkins/jobs
              while read stagelog; do
                  # If we encountered the cooresponding gzip file, then the prior gzip operation on this file
                  # was interruped or failed for some reason. Note the error, clean up, and move on.
                  if [[ -f \$stagelog.gz ]]; then
                    echo "Both \$stagelog and \$stagelog.gz exist. Was gzip previously interrupted? Removing \$stagelog.gz..."
                    rm -f \$stagelog.gz
                  fi
                  echo "Compressing log: \$stagelog..."
                  gzip \$stagelog
                  _rc=\$?
                  if [ \$_rc -ne '0' ]; then
                    echo "gzip file \$stagelog failed with a non-zero response code of: \$_rc. Setting job stage response code to: \$_rc. This will fail the stage."
                    rc=\$_rc
                  fi
              done < <(find . -regex '.+/builds/[0-9]+/\\([0-9]+\\.\\)?log' -mtime +1)
              exit \${rc:-0}
            """
          }
        }
      } // globalWraps
